{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile data.txt\n",
        "my name is sudhanshu kumar , i work with euron , Helping Millions of Students Succeed\n",
        "Sudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission.\n",
        "Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market.\n",
        "Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds.\n",
        "They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.\n",
        "In 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore.\n",
        "While this acquisition was a significant milestone, Sudhanshu remained focused on his mission.\n",
        "Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.\n",
        "Helping Millions of Students Succeed\n",
        "Sudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission.\n",
        "Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market.\n",
        "Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds.\n",
        "They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.\n",
        "In 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore.\n",
        "While this acquisition was a significant milestone, Sudhanshu remained focused on his mission.\n",
        "Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.Sudhanshu Kumar's life is a story of triumph over adversity, driven by the belief in the transformative power of education.\n",
        "Born in Jamshedpur, Jharkhand, India, to a family of very modest means, Sudhanshu's early years were marked by financial hardship.\n",
        "His surroundings offered little opportunity, and resources were limited, yet he understood from a young age that education could be his ticket out of poverty.\n",
        "While many would have been daunted by the lack of support and opportunity, Sudhanshu was relentless in his pursuit of knowledge.\n",
        "He knew that education had the power to change lives, and he was determined to leverage it to create a better future for himself and his family.\n",
        "Despite the numerous challenges along the way, Sudhanshu excelled academically, eventually earning a degree in Computer Science and Engineering (CSE).\n",
        "After completing his education, Sudhanshu began his professional journey in the tech industry, working with prestigious companies like Wipro, Deloitte, Verizon Labs, and Ernst & Young.\n",
        "During this time, he gained expertise in various technologies and frameworks, including SAP WebDynpro, Fiori UI5 HANA, Java, Big Data, Data Analytics, and more.\n",
        "He became a well-rounded technologist, well-respected in his field.\n",
        "\n",
        "Despite his growing success, Sudhanshu never forgot his roots.\n",
        "He knew that there were many others who, like him, came from humble backgrounds and were looking for an opportunity to change their lives through education.\n",
        "It was during this time that Sudhanshu realized a harsh truth: quality education was often inaccessible to those who needed it the most.\n",
        "The high cost of education barred millions of people from pursuing their dreams, especially in tech fields that required specialized skills.\n",
        "Fueled by his passion for making education accessible, Sudhanshu decided to take action.\n",
        "In 2019, he founded iNeuron Intelligence Private Limited, an edtech platform that would make tech upskilling affordable and accessible for everyone.\n",
        "His mission was clear: to provide high-quality courses at a price so low that even those from the most disadvantaged backgrounds could afford to learn.\n",
        "iNeuron was designed to be more than just an online learning platform.\n",
        "It offered a comprehensive bundle of resources, including courses, books, hands-on projects, and live classes, making sure that learners could gain real-world, applicable skills.\n",
        "Most importantly, iNeuron was priced to ensure no student would be left behind due to financial constraints.\n",
        "The company quickly gained traction, thanks to Sudhanshu's focus on affordability and quality.\n",
        "In 2021, iNeuron raised $3 million in funding from S. Chand, a leading education publisher.\n",
        "This allowed iNeuron to expand its offerings and reach a larger audience.\n",
        "Building on the success of iNeuron, Sudhanshu is now leading Euron, a unified platform for tech upskilling.\n",
        "Euron is designed for enterprises, schools, colleges, government organizations, and individuals looking to improve their tech skills.\n",
        "The platform provides a comprehensive bundle of resources, including courses, books, live classes, and projects.\n",
        "Euron's unique offering is its ability to provide licenses at scale—organizations can subscribe to provide their teams with unlimited access to learning materials for just 1600 INR per year per license.\n",
        "For individuals, Euron Plus offers a similar plan, priced at 2900 INR per year, giving learners access to all of Euron's content, along with 24/7 support through Euron Assist.\n",
        "The idea is simple: anyone, anywhere, should have the opportunity to upskill without financial barriers.\n",
        "The Euron Motto: Education for All, Without Limits\n",
        "\n",
        "At the heart of Euron's philosophy is a single, powerful idea: Education for All, Without Limits.\n",
        "Sudhanshu believes that every person deserves the chance to learn, grow, and succeed, regardless of their financial situation or background.\n",
        "This belief is what drives Euron's mission to make tech education not just affordable but also accessible to anyone, anywhere in the world."
      ],
      "metadata": {
        "id": "2l6fLNLzvxNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2bebe7-2aec-4bef-8b0d-6308055992f8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "metadata": {
        "id": "2zQqi_NwH0rX"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load Data\n",
        "with open(\"data.txt\", 'r', encoding='utf-8') as f:\n",
        "    text_data = f.read()"
      ],
      "metadata": {
        "id": "lD4xAWSUI4R0"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create Tokenizer\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts([text_data])"
      ],
      "metadata": {
        "id": "irLaCSyrI7GW"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Convert to Sequence\n",
        "sequence = tokenizer.texts_to_sequences([text_data])[0]"
      ],
      "metadata": {
        "id": "VHfQDX4QI962"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Save Tokenizer\n",
        "with open(\"tokenizer.pkl\", 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)"
      ],
      "metadata": {
        "id": "9HFVMJ5nJAZR"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Create Dataset\n",
        "max_seq_length = 50\n",
        "\n",
        "def create_dataset(seq, window_size=max_seq_length):\n",
        "    inputs, labels = [], []\n",
        "    for i in range(len(seq) - window_size):\n",
        "        inputs.append(seq[i:i+window_size])\n",
        "        labels.append(seq[i+1:i+window_size+1])\n",
        "    return np.array(inputs), np.array(labels)\n",
        "\n",
        "x_data, y_data = create_dataset(sequence)"
      ],
      "metadata": {
        "id": "JGYE3sguJDP-"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Define PositionalEncoding - FIXED VERSION\n",
        "class PositionalEncoding(layers.Layer):\n",
        "    def __init__(self, max_len=None, d_model=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "\n",
        "        if max_len is not None and d_model is not None:\n",
        "            pos = np.arange(max_len)[:, np.newaxis]\n",
        "            i = np.arange(d_model)[np.newaxis, :]\n",
        "            angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "            angle_rads = pos * angle_rates\n",
        "            angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "            angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "            self.pos_encoding = tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)\n",
        "\n",
        "    def call(self, x):\n",
        "        return x + self.pos_encoding[:, :tf.shape(x)[1], :]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"max_len\": self.max_len,\n",
        "            \"d_model\": self.d_model\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "IPm-YeCuJFvF"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Define Transformer Block\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.dropout_rate = dropout\n",
        "\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            layers.Dense(ff_dim, activation='relu'),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(dropout)\n",
        "        self.dropout2 = layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"ff_dim\": self.ff_dim,\n",
        "            \"dropout\": self.dropout_rate,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "TKGEBuEGJQBE"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Define Model Hyperparameters and Build the Model\n",
        "vocab_size = 2000      # Reduced to better fit the actual vocabulary size\n",
        "max_seq_len = 50       # Kept the same, good sequence length\n",
        "embed_dim = 128        # Reduced for a smaller, more efficient model\n",
        "num_heads = 4          # Reduced in proportion to embed_dim (must be a divisor)\n",
        "ff_dim = 512           # Reduced, typically 4x embed_dim\n",
        "num_layers = 3         # Reduced to prevent overfitting on small data\n",
        "batch_size = 16        # Smaller batch size can help with generalization\n",
        "epochs = 50            # Increased epochs, but we will use Early Stopping\n"
      ],
      "metadata": {
        "id": "5AHzsxF9JT2v"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gpt_model():\n",
        "    inputs = layers.Input(shape=(max_seq_len,))\n",
        "    x = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\n",
        "    x = PositionalEncoding(max_seq_len, embed_dim)(x)\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        x = transformer_block(embed_dim, num_heads, ff_dim)(x)\n",
        "\n",
        "    outputs = layers.Dense(vocab_size, activation='softmax')(x)\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model = build_gpt_model()\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hTbh-iQtJnFk"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Train the Model\n",
        "model.fit(x_data,y_data , batch_size=batch_size , epochs=epochs ,validation_split=.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwz_LAZJJ1TV",
        "outputId": "851d7bee-6524-4760-ca02-3dfd7b912aa9"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 243ms/step - accuracy: 0.0224 - loss: 6.4420 - val_accuracy: 0.0375 - val_loss: 7.4774\n",
            "Epoch 2/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0325 - loss: 5.3619 - val_accuracy: 0.0375 - val_loss: 7.6988\n",
            "Epoch 3/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0332 - loss: 5.3669 - val_accuracy: 0.0375 - val_loss: 7.9321\n",
            "Epoch 4/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0334 - loss: 5.3510 - val_accuracy: 0.0588 - val_loss: 7.9837\n",
            "Epoch 5/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0327 - loss: 5.3558 - val_accuracy: 0.0375 - val_loss: 8.0390\n",
            "Epoch 6/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0337 - loss: 5.3679 - val_accuracy: 0.0375 - val_loss: 8.0943\n",
            "Epoch 7/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0337 - loss: 5.3449 - val_accuracy: 0.0375 - val_loss: 8.1871\n",
            "Epoch 8/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0348 - loss: 5.3453 - val_accuracy: 0.0375 - val_loss: 8.2207\n",
            "Epoch 9/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0323 - loss: 5.3345 - val_accuracy: 0.0375 - val_loss: 8.2051\n",
            "Epoch 10/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0326 - loss: 5.3500 - val_accuracy: 0.0375 - val_loss: 8.2473\n",
            "Epoch 11/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0344 - loss: 5.3285 - val_accuracy: 0.0375 - val_loss: 8.2308\n",
            "Epoch 12/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0345 - loss: 5.3366 - val_accuracy: 0.0719 - val_loss: 8.1516\n",
            "Epoch 13/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1198 - loss: 4.8625 - val_accuracy: 0.1333 - val_loss: 6.6856\n",
            "Epoch 14/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5925 - loss: 1.7540 - val_accuracy: 0.1598 - val_loss: 6.9275\n",
            "Epoch 15/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8086 - loss: 0.6996 - val_accuracy: 0.1901 - val_loss: 6.9654\n",
            "Epoch 16/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9627 - loss: 0.2160 - val_accuracy: 0.2252 - val_loss: 7.0701\n",
            "Epoch 17/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.0871 - val_accuracy: 0.2237 - val_loss: 7.0426\n",
            "Epoch 18/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9900 - loss: 0.0534 - val_accuracy: 0.2402 - val_loss: 7.2427\n",
            "Epoch 19/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0401 - val_accuracy: 0.2304 - val_loss: 7.3795\n",
            "Epoch 20/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0316 - val_accuracy: 0.2477 - val_loss: 7.3221\n",
            "Epoch 21/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9965 - loss: 0.0210 - val_accuracy: 0.2390 - val_loss: 7.4417\n",
            "Epoch 22/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0225 - val_accuracy: 0.2462 - val_loss: 7.4203\n",
            "Epoch 23/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0180 - val_accuracy: 0.2590 - val_loss: 7.4641\n",
            "Epoch 24/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0147 - val_accuracy: 0.2563 - val_loss: 7.5582\n",
            "Epoch 25/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0148 - val_accuracy: 0.2440 - val_loss: 7.5334\n",
            "Epoch 26/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9972 - loss: 0.0144 - val_accuracy: 0.2662 - val_loss: 7.5713\n",
            "Epoch 27/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9983 - loss: 0.0098 - val_accuracy: 0.2649 - val_loss: 7.6440\n",
            "Epoch 28/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0071 - val_accuracy: 0.2686 - val_loss: 7.5699\n",
            "Epoch 29/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0061 - val_accuracy: 0.2667 - val_loss: 7.7187\n",
            "Epoch 30/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.0054 - val_accuracy: 0.2699 - val_loss: 7.6298\n",
            "Epoch 31/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0053 - val_accuracy: 0.2719 - val_loss: 7.7360\n",
            "Epoch 32/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0058 - val_accuracy: 0.2674 - val_loss: 7.6859\n",
            "Epoch 33/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0036 - val_accuracy: 0.2733 - val_loss: 7.7546\n",
            "Epoch 34/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0053 - val_accuracy: 0.2662 - val_loss: 7.8544\n",
            "Epoch 35/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0035 - val_accuracy: 0.2649 - val_loss: 7.7166\n",
            "Epoch 36/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.2652 - val_loss: 7.7276\n",
            "Epoch 37/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0045 - val_accuracy: 0.2760 - val_loss: 7.8615\n",
            "Epoch 38/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0026 - val_accuracy: 0.2758 - val_loss: 7.8930\n",
            "Epoch 39/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0027 - val_accuracy: 0.2822 - val_loss: 7.8972\n",
            "Epoch 40/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 0.2657 - val_loss: 7.7557\n",
            "Epoch 41/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0100 - val_accuracy: 0.2422 - val_loss: 8.0197\n",
            "Epoch 42/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9976 - loss: 0.0145 - val_accuracy: 0.2677 - val_loss: 7.7669\n",
            "Epoch 43/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0182 - val_accuracy: 0.2736 - val_loss: 7.7758\n",
            "Epoch 44/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0058 - val_accuracy: 0.2891 - val_loss: 7.9047\n",
            "Epoch 45/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0038 - val_accuracy: 0.2847 - val_loss: 7.9036\n",
            "Epoch 46/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.2820 - val_loss: 7.9770\n",
            "Epoch 47/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.2928 - val_loss: 7.9990\n",
            "Epoch 48/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.2857 - val_loss: 8.0892\n",
            "Epoch 49/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.2923 - val_loss: 8.1646\n",
            "Epoch 50/50\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.4815e-04 - val_accuracy: 0.2881 - val_loss: 8.1024\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c30905d89e0>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Save Model\n",
        "model.save('gpt_test_genai_class.keras')\n",
        "print(\"Model saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njKJ5gReKiV3",
        "outputId": "bc8d2919-fcab-42e1-bf23-8f499e0ee555"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOW USE THE MODEL\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def generate_text(seed_text, model, tokenizer, num_tokens=50, temperature=1.0):\n",
        "    for _ in range(num_tokens):\n",
        "        token_seq = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_seq = token_seq[-max_seq_len:]\n",
        "        padded_seq = pad_sequences([token_seq], maxlen=max_seq_len)\n",
        "\n",
        "        preds = model.predict(padded_seq, verbose=0)[0, -1]\n",
        "        preds = np.asarray(preds).astype('float64')\n",
        "\n",
        "        preds = np.log(preds + 1e-9) / temperature\n",
        "        preds = np.exp(preds) / np.sum(np.exp(preds))\n",
        "\n",
        "        next_token_id = np.random.choice(len(preds), p=preds)\n",
        "        next_word = tokenizer.index_word.get(next_token_id, '')\n",
        "\n",
        "        seed_text += ' ' + next_word\n",
        "\n",
        "        if next_word == '':\n",
        "            break\n",
        "\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "KBB9ST4_MejL"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test generation\n",
        "seed_text = \"who is sudhanshu\"\n",
        "generated = generate_text(seed_text, model, tokenizer, num_tokens=50, temperature=1.0)\n",
        "print(\"\\nGenerated Text:\")\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iImbtjNxMjmZ",
        "outputId": "676c597c-f699-4a49-ed55-4418a31da575"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text:\n",
            "who is sudhanshu realized a similar plan priced at 2900 inr per year giving learners access to all of euron's content along with 24 7 support through euron assist the company quickly gained traction thanks to sudhanshu's early years were looking for himself and his surroundings to financial hardship his surroundings offered little\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXyfJVFoMm4e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}